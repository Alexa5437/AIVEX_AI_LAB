{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQE+BebP0iL+ktmhBT7mKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexa5437/AIVEX_AI_LAB/blob/main/Lab_2_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLAGIARISM DETECTION SUBMISSION PROBLEM"
      ],
      "metadata": {
        "id": "aKaJRKD9TdFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZxV0oVhTb3R",
        "outputId": "27809083-67c4-4521-fb66-13c26b9d4964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1 - Identical Documents, Plagiarism Score: 10\n",
            "Test Case 2 - Slightly Modified Document, Plagiarism Score: 8\n",
            "Test Case 3 - Completely Different Documents, Plagiarism Score: 6\n",
            "Test Case 4 - Partial Overlap, Plagiarism Score: 8\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from queue import PriorityQueue\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "# Compute normalized Levenshtein distance (edit distance) between two sentences\n",
        "def levenshtein_distance(s1, s2):\n",
        "    len_s1, len_s2 = len(s1), len(s2)\n",
        "\n",
        "    if len_s1 == 0:\n",
        "        return len_s2\n",
        "    if len_s2 == 0:\n",
        "        return len_s1\n",
        "\n",
        "    if len(s1) < len(s2):\n",
        "        s1, s2 = s2, s1\n",
        "\n",
        "    previous_row = range(len(s2) + 1)\n",
        "    for i, c1 in enumerate(s1):\n",
        "        current_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            insertions = previous_row[j + 1] + 1\n",
        "            deletions = current_row[j] + 1\n",
        "            substitutions = previous_row[j] + (c1 != c2)\n",
        "            current_row.append(min(insertions, deletions, substitutions))\n",
        "        previous_row = current_row\n",
        "\n",
        "    # Normalize by the length of the longer sentence\n",
        "    return previous_row[-1] / max(len_s1, len_s2)\n",
        "\n",
        "# A* search algorithm to find the optimal sentence alignment\n",
        "def a_star_search(sentences_doc1, sentences_doc2):\n",
        "    def heuristic(i, j):\n",
        "        # Heuristic: Assume remaining sentences will all be different\n",
        "        return (len(sentences_doc1) - i) + (len(sentences_doc2) - j)\n",
        "\n",
        "    open_states = PriorityQueue()\n",
        "    open_states.put((0, (0, 0, 0)))  # (f_cost, (i, j, g_cost))\n",
        "    closed_states = set()  # Fix the indentation here\n",
        "\n",
        "    while not open_states.empty():\n",
        "        f_cost, (i, j, g_cost) = open_states.get()\n",
        "\n",
        "        if (i, j) in closed_states:\n",
        "            continue\n",
        "        closed_states.add((i, j))\n",
        "\n",
        "        # Check if we've reached the end of both documents\n",
        "        if i == len(sentences_doc1) and j == len(sentences_doc2):\n",
        "            return g_cost  # Return total alignment cost\n",
        "\n",
        "        # Explore alignment\n",
        "        if i < len(sentences_doc1) and j < len(sentences_doc2):\n",
        "            alignment_cost = g_cost + levenshtein_distance(sentences_doc1[i], sentences_doc2[j])\n",
        "            open_states.put((alignment_cost + heuristic(i + 1, j + 1), (i + 1, j + 1, alignment_cost)))\n",
        "\n",
        "        # Explore skipping sentence from doc1\n",
        "        if i < len(sentences_doc1):\n",
        "            open_states.put((g_cost + 1 + heuristic(i + 1, j), (i + 1, j, g_cost + 1)))\n",
        "\n",
        "        # Explore skipping sentence from doc2\n",
        "        if j < len(sentences_doc2):\n",
        "            open_states.put((g_cost + 1 + heuristic(i, j + 1), (i, j + 1, g_cost + 1)))\n",
        "\n",
        "    return float('inf')  # No solution found\n",
        "\n",
        "\n",
        "def detect_plagiarism(doc1, doc2):\n",
        "    sentences_doc1 = preprocess_text(doc1)\n",
        "    sentences_doc2 = preprocess_text(doc2)\n",
        "    alignment_cost = a_star_search(sentences_doc1, sentences_doc2)\n",
        "\n",
        "    # Maximum possible cost is aligning every sentence by skipping\n",
        "    max_possible_cost = (len(sentences_doc1) + len(sentences_doc2))\n",
        "\n",
        "    # Calculate plagiarism score\n",
        "    if alignment_cost == float('inf'):\n",
        "        plagiarism_score = 0\n",
        "    else:\n",
        "        normalized_cost = alignment_cost / max_possible_cost\n",
        "        plagiarism_score = max(0, 10 - (normalized_cost * 10))  # Ensure non-negative score\n",
        "\n",
        "    return round(plagiarism_score)\n",
        "\n",
        "\n",
        "# Test cases\n",
        "def run_test_cases():\n",
        "    # Test Case 1: Identical Documents\n",
        "    doc1 = \"Machine learning algorithms can classify images.\"\n",
        "    doc2 = \"Machine learning algorithms can classify images.\"\n",
        "    plagiarism_score = detect_plagiarism(doc1, doc2)\n",
        "    print(f\"Test Case 1 - Identical Documents, Plagiarism Score: {plagiarism_score}\")\n",
        "\n",
        "    # Test Case 2: Slightly Modified Document\n",
        "    doc1 = \"Machine learning algorithms can classify images.\"\n",
        "    doc2 = \"Algorithms for machine learning are able to classify images.\"\n",
        "    plagiarism_score = detect_plagiarism(doc1, doc2)\n",
        "    print(f\"Test Case 2 - Slightly Modified Document, Plagiarism Score: {plagiarism_score}\")\n",
        "\n",
        "    # Test Case 3: Completely Different Documents\n",
        "    doc1 = \"Machine learning algorithms can classify images.\"\n",
        "    doc2 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "    plagiarism_score = detect_plagiarism(doc1, doc2)\n",
        "    print(f\"Test Case 3 - Completely Different Documents, Plagiarism Score: {plagiarism_score}\")\n",
        "\n",
        "    # Test Case 4: Partial Overlap\n",
        "    doc1 = \"Machine learning algorithms can classify images. Deep learning improves accuracy.\"\n",
        "    doc2 = \"Deep learning is a technique in machine learning that improves accuracy.\"\n",
        "    plagiarism_score = detect_plagiarism(doc1, doc2)\n",
        "    print(f\"Test Case 4 - Partial Overlap, Plagiarism Score: {plagiarism_score}\")\n",
        "\n",
        "# Run all test cases\n",
        "run_test_cases()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ywj_T5PTkh1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}